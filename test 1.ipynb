{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-03-02 18:33:50--  http://max-training-data.s3-api.us-geo.objectstorage.softlayer.net/noaa-weather/jfk_weather.tar.gz\nResolving max-training-data.s3-api.us-geo.objectstorage.softlayer.net (max-training-data.s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to max-training-data.s3-api.us-geo.objectstorage.softlayer.net (max-training-data.s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2575759 (2.5M) [application/x-tar]\nSaving to: 'jfk_weather.tar.gz'\n\n100%[======================================>] 2,575,759   4.07MB/s   in 0.6s   \n\n2020-03-02 18:33:51 (4.07 MB/s) - 'jfk_weather.tar.gz' saved [2575759/2575759]\n\n./._jfk_weather.csv\njfk_weather.csv\n"
                },
                {
                    "data": {
                        "text/plain": "<bound method DataFrame.show of DataFrame[STATION: string, STATION_NAME: string, ELEVATION: double, LATITUDE: double, LONGITUDE: double, DATE: string, REPORTTPYE: string, HOURLYSKYCONDITIONS: string, HOURLYVISIBILITY: string, HOURLYPRSENTWEATHERTYPE: string, HOURLYDRYBULBTEMPF: string, HOURLYDRYBULBTEMPC: string, HOURLYWETBULBTEMPF: string, HOURLYWETBULBTEMPC: string, HOURLYDewPointTempF: string, HOURLYDewPointTempC: string, HOURLYRelativeHumidity: string, HOURLYWindSpeed: string, HOURLYWindDirection: string, HOURLYWindGustSpeed: int, HOURLYStationPressure: string, HOURLYPressureTendency: int, HOURLYPressureChange: string, HOURLYSeaLevelPressure: string, HOURLYPrecip: string, HOURLYAltimeterSetting: string, DAILYMaximumDryBulbTemp: int, DAILYMinimumDryBulbTemp: int, DAILYAverageDryBulbTemp: int, DAILYDeptFromNormalAverageTemp: double, DAILYAverageRelativeHumidity: int, DAILYAverageDewPointTemp: int, DAILYAverageWetBulbTemp: int, DAILYHeatingDegreeDays: int, DAILYCoolingDegreeDays: int, DAILYSunrise: int, DAILYSunset: int, DAILYWeather: string, DAILYPrecip: string, DAILYSnowfall: string, DAILYSnowDepth: string, DAILYAverageStationPressure: double, DAILYAverageSeaLevelPressure: double, DAILYAverageWindSpeed: double, DAILYPeakWindSpeed: int, PeakWindDirection: int, DAILYSustainedWindSpeed: int, DAILYSustainedWindDirection: int, MonthlyMaximumTemp: double, MonthlyMinimumTemp: double, MonthlyMeanTemp: double, MonthlyAverageRH: string, MonthlyDewpointTemp: string, MonthlyWetBulbTemp: string, MonthlyAvgHeatingDegreeDays: int, MonthlyAvgCoolingDegreeDays: int, MonthlyStationPressure: double, MonthlySeaLevelPressure: double, MonthlyAverageWindSpeed: double, MonthlyTotalSnowfall: string, MonthlyDeptFromNormalMaximumTemp: double, MonthlyDeptFromNormalMinimumTemp: double, MonthlyDeptFromNormalAverageTemp: double, MonthlyDeptFromNormalPrecip: string, MonthlyTotalLiquidPrecip: string, MonthlyGreatestPrecip: string, MonthlyGreatestPrecipDate: string, MonthlyGreatestSnowfall: string, MonthlyGreatestSnowfallDate: string, MonthlyGreatestSnowDepth: string, MonthlyGreatestSnowDepthDate: int, MonthlyDaysWithGT90Temp: int, MonthlyDaysWithLT32Temp: int, MonthlyDaysWithGT32Temp: int, MonthlyDaysWithLT0Temp: int, MonthlyDaysWithGT001Precip: string, MonthlyDaysWithGT010Precip: string, MonthlyDaysWithGT1Snow: int, MonthlyMaxSeaLevelPressureValue: string, MonthlyMaxSeaLevelPressureDate: int, MonthlyMaxSeaLevelPressureTime: int, MonthlyMinSeaLevelPressureValue: string, MonthlyMinSeaLevelPressureDate: int, MonthlyMinSeaLevelPressureTime: int, MonthlyTotalHeatingDegreeDays: string, MonthlyTotalCoolingDegreeDays: string, MonthlyDeptFromNormalHeatingDD: string, MonthlyDeptFromNormalCoolingDD: string, MonthlyTotalSeasonToDateHeatingDD: int, MonthlyTotalSeasonToDateCoolingDD: int]>"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# delete files from previous runs\n!rm -f jfk_weather*\n\n# download the file containing the data in CSV format\n!wget http://max-training-data.s3-api.us-geo.objectstorage.softlayer.net/noaa-weather/jfk_weather.tar.gz\n\n# extract the data\n!tar xvfz jfk_weather.tar.gz\n    \n# create a dataframe out of it by using the first row as field names and trying to infer a schema based on contents\ndf = spark.read.option(\"header\", \"true\").option(\"inferSchema\",\"true\").csv('jfk_weather.csv')\n\n# register a corresponding query table\ndf.createOrReplaceTempView('df')\ndf.show"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": "\nimport random\nrandom.seed(42)\n\nfrom pyspark.sql.functions import translate, col\n\ndf_cleaned = df \\\n    .withColumn(\"HOURLYWindSpeed\", df.HOURLYWindSpeed.cast('double')) \\\n    .withColumn(\"HOURLYWindDirection\", df.HOURLYWindDirection.cast('double')) \\\n    .withColumn(\"HOURLYStationPressure\", translate(col(\"HOURLYStationPressure\"), \"s,\", \"\")) \\\n    .withColumn(\"HOURLYPrecip\", translate(col(\"HOURLYPrecip\"), \"s,\", \"\")) \\\n    .withColumn(\"HOURLYRelativeHumidity\", translate(col(\"HOURLYRelativeHumidity\"), \"*\", \"\")) \\\n    .withColumn(\"HOURLYDRYBULBTEMPC\", translate(col(\"HOURLYDRYBULBTEMPC\"), \"*\", \"\")) \\\n\ndf_cleaned =   df_cleaned \\\n                    .withColumn(\"HOURLYStationPressure\", df_cleaned.HOURLYStationPressure.cast('double')) \\\n                    .withColumn(\"HOURLYPrecip\", df_cleaned.HOURLYPrecip.cast('double')) \\\n                    .withColumn(\"HOURLYRelativeHumidity\", df_cleaned.HOURLYRelativeHumidity.cast('double')) \\\n                    .withColumn(\"HOURLYDRYBULBTEMPC\", df_cleaned.HOURLYDRYBULBTEMPC.cast('double')) \\\n\ndf_filtered = df_cleaned.filter(\"\"\"\n    HOURLYWindSpeed <> 0\n    and HOURLYWindDirection <> 0\n    and HOURLYStationPressure <> 0\n    and HOURLYPressureTendency <> 0\n    and HOURLYPressureTendency <> 0\n    and HOURLYPrecip <> 0\n    and HOURLYRelativeHumidity <> 0\n    and HOURLYDRYBULBTEMPC <> 0\n\"\"\")"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[ 1.        ,  0.06306013, -0.4204518 ],\n       [ 0.06306013,  1.        , -0.19199348],\n       [-0.4204518 , -0.19199348,  1.        ]])"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from pyspark.ml.feature import VectorAssembler\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYWindDirection\",\"HOURLYStationPressure\"],\n                                  outputCol=\"features\")\ndf_pipeline = vectorAssembler.transform(df_filtered)\nfrom pyspark.ml.stat import Correlation\nCorrelation.corr(df_pipeline,\"features\").head()[0].toArray()"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "splits = df_filtered.randomSplit([0.8, 0.2])\ndf_train = splits[0]\ndf_test = splits[1]"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.feature import StringIndexer, OneHotEncoder\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import Normalizer\nfrom pyspark.ml import Pipeline\n\nvectorAssembler = VectorAssembler(inputCols=[\n                                    \"HOURLYWindDirection\",\n                                    \"ELEVATION\",\n                                    \"HOURLYStationPressure\"],\n                                  outputCol=\"features\")\n\nnormalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": "def regression_metrics(prediction):\n    from pyspark.ml.evaluation import RegressionEvaluator\n    evaluator = RegressionEvaluator(\n    labelCol=\"HOURLYWindSpeed\", predictionCol=\"prediction\", metricName=\"rmse\")\n    rmse = evaluator.evaluate(prediction)\n    print(\"RMSE on test data = %g\" % rmse)"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "RMSE on test data = 3.47898\n"
                }
            ],
            "source": "from pyspark.ml.regression import LinearRegression\n\n\nlr = LinearRegression(labelCol=\"HOURLYWindSpeed\", featuresCol='features_norm', maxIter=100, regParam=0.0, elasticNetParam=0.0)\npipeline = Pipeline(stages=[vectorAssembler, normalizer,lr])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nregression_metrics(prediction)"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "RMSE on test data = 7.01428\n"
                }
            ],
            "source": "from pyspark.ml.regression import GBTRegressor\ngbt = GBTRegressor(labelCol=\"HOURLYWindSpeed\", maxIter=100)\npipeline = Pipeline(stages=[vectorAssembler, normalizer,gbt])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nregression_metrics(prediction)"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml.feature import Bucketizer, OneHotEncoder\nbucketizer = Bucketizer(splits=[ 0, 180, float('Inf') ],inputCol=\"HOURLYWindDirection\", outputCol=\"HOURLYWindDirectionBucketized\")\nencoder = OneHotEncoder(inputCol=\"HOURLYWindDirectionBucketized\", outputCol=\"HOURLYWindDirectionOHE\")"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "def classification_metrics(prediction):\n    from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n    mcEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"HOURLYWindDirectionBucketized\")\n    accuracy = mcEval.evaluate(prediction)\n    print(\"Accuracy on test data = %g\" % accuracy)"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy on test data = 0.613208\n"
                }
            ],
            "source": "from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"HOURLYWindDirectionBucketized\", maxIter=10)\n#,\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"\n\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\"],\n                                  outputCol=\"features\")\n\npipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,lr])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nclassification_metrics(prediction)"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy on test data = 0.672956\n"
                }
            ],
            "source": "from pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"HOURLYWindDirectionBucketized\", numTrees=30)\n\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\",\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"],\n                                  outputCol=\"features\")\n\npipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,rf])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nclassification_metrics(prediction)"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy on test data = 0.688679\n"
                }
            ],
            "source": "from pyspark.ml.classification import GBTClassifier\ngbt = GBTClassifier(labelCol=\"HOURLYWindDirectionBucketized\", maxIter=100)\n\nvectorAssembler = VectorAssembler(inputCols=[\"HOURLYWindSpeed\",\"HOURLYDRYBULBTEMPC\",\"ELEVATION\",\"HOURLYStationPressure\",\"HOURLYPressureTendency\",\"HOURLYPrecip\"],\n                                  outputCol=\"features\")\n\npipeline = Pipeline(stages=[bucketizer,vectorAssembler,normalizer,gbt])\nmodel = pipeline.fit(df_train)\nprediction = model.transform(df_test)\nclassification_metrics(prediction)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}